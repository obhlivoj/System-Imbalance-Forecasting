{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickles(folder_path):\n",
    "    all_data = {} \n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pkl'):  # Check if the file is a pickle file\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                # Unpickle the file and store its contents in the dictionary\n",
    "                data = pickle.load(file)\n",
    "                all_data[filename] = data\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mlp_fl_val_res.pkl', 'tft_val_res.pkl', 'transformer_fl_val_res.pkl', 'xgboost_fl_val_res.pkl'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = '_results_fl_val'\n",
    "val_data = load_pickles(folder_path)\n",
    "val_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\obhlivoj\\DP\\System-Imbalance-Forecasting\\models\\xgboost')\n",
    "\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from train import get_ds\n",
    "from config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_src, test_src = [], []\n",
    "for k in range(8):    \n",
    "    cfg = get_config()\n",
    "    cfg['tgt_step'] = k\n",
    "    cfg['path_pickle'] = '../data/data_TS/'\n",
    "\n",
    "    cfg[\"exo_vars\"] = ['total_load']\n",
    "    cfg[\"forward_vars\"] = [\"most_recent_forecast_load\"]\n",
    "\n",
    "    _, val_scl, test_scl = get_ds(cfg, return_raw=True)\n",
    "\n",
    "    src_val, src_test = [], []\n",
    "    for dt in val_scl:\n",
    "        src_val.append(dt['x_input'].numpy())\n",
    "    for dt in test_scl:\n",
    "        src_test.append(dt['x_input'].numpy())\n",
    "\n",
    "    val_src.append(np.stack(src_val))\n",
    "    test_src.append(np.stack(src_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_models_cat = []\n",
    "meta_forest_cat = []\n",
    "for k in range(8):    \n",
    "    preds_mlp = val_data['mlp_fl_val_res.pkl']['preds'][k].squeeze().cpu().numpy()\n",
    "    preds_tft = val_data['tft_val_res.pkl']['preds'][:,k]\n",
    "    preds_tf = val_data['transformer_fl_val_res.pkl']['preds'][:,k].squeeze().numpy()\n",
    "    preds_xgb = val_data['xgboost_fl_val_res.pkl']['preds'][k]\n",
    "\n",
    "    y_true = val_data['mlp_fl_val_res.pkl']['gt'][k].squeeze().cpu().numpy()\n",
    "    min_size = np.min((preds_mlp.shape[0], preds_tft.shape[0], preds_tf.shape[0], preds_xgb.shape[0]))\n",
    "\n",
    "    stacked_preds = np.column_stack((preds_mlp[:min_size], preds_tft[:min_size], preds_tf[:min_size], preds_xgb[:min_size]))\n",
    "    # lr\n",
    "    meta_model = LinearRegression()\n",
    "    meta_model.fit(stacked_preds, y_true[:min_size])\n",
    "    meta_models_cat.append(meta_model)\n",
    "    # rf\n",
    "    param_grid = {\n",
    "    'n_estimators': [64, 128, 256, 512],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    }\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring=scorer, cv=tscv, n_jobs=-1, refit=True)\n",
    "    #grid_search.fit(np.concatenate((stacked_preds, val_src[k][:min_size]), axis=1), y_true[:min_size]) 3. method\n",
    "    grid_search.fit(stacked_preds, y_true[:min_size])\n",
    "\n",
    "    meta_forest_cat.append(grid_search.best_estimator_)\n",
    "    # meta_forest.fit(stacked_preds, y_true[:min_size]) # 1. method\n",
    "\n",
    "    # meta_forest = RandomForestRegressor(n_estimators=80, max_depth=12, random_state=69) # 2. method\n",
    "    # meta_forest.fit(np.concatenate((stacked_preds, val_src[k][:min_size]), axis=1), y_true[:min_size])\n",
    "    # meta_forest_cat.append(meta_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: max_depth: 4, n_estimators: 64\n",
      "1: max_depth: 4, n_estimators: 256\n",
      "2: max_depth: 3, n_estimators: 64\n",
      "3: max_depth: 3, n_estimators: 512\n",
      "4: max_depth: 3, n_estimators: 256\n",
      "5: max_depth: 3, n_estimators: 64\n",
      "6: max_depth: 3, n_estimators: 128\n",
      "7: max_depth: 4, n_estimators: 64\n"
     ]
    }
   ],
   "source": [
    "for k, mod in enumerate(meta_forest_cat):\n",
    "    print(f'{k}: max_depth: {mod.max_depth}, n_estimators: {mod.n_estimators}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mlp_fl_test_res.pkl', 'tft_test_res.pkl', 'transformer_fl_test_res.pkl', 'xgboost_fl_test_res.pkl'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = '_results_fl'\n",
    "unpickled_data = load_pickles(folder_path)\n",
    "unpickled_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(method: str = \"simple\", meta_models_cat = None):\n",
    "    rmse = {}\n",
    "    mae = {}\n",
    "    r2 = {}\n",
    "\n",
    "    for k in range(8):\n",
    "        preds_mlp = unpickled_data['mlp_fl_test_res.pkl']['preds'][k].squeeze().cpu().numpy()\n",
    "        preds_tft = unpickled_data['tft_test_res.pkl']['preds'][:,k]\n",
    "        preds_tf = unpickled_data['transformer_fl_test_res.pkl']['preds'][:,k].squeeze().numpy()\n",
    "        preds_xgb = unpickled_data['xgboost_fl_test_res.pkl']['preds'][k]\n",
    "\n",
    "        y_true = unpickled_data['mlp_fl_test_res.pkl']['gt'][k].squeeze().cpu().numpy()\n",
    "\n",
    "        min_size = np.min((preds_mlp.shape[0], preds_tft.shape[0], preds_tf.shape[0], preds_xgb.shape[0]))\n",
    "\n",
    "        if method == \"simple\":\n",
    "            res = (preds_mlp[:min_size] + preds_tft[:min_size] + preds_tf[:min_size] + preds_xgb[:min_size]) / 4\n",
    "        elif method == \"lm\":\n",
    "            stacked_predictions = np.column_stack((preds_mlp[:min_size], preds_tft[:min_size], preds_tf[:min_size], preds_xgb[:min_size]))\n",
    "            res = meta_models_cat[k].predict(stacked_predictions)\n",
    "        elif method == \"rf\":\n",
    "            stacked_predictions = np.column_stack((preds_mlp[:min_size], preds_tft[:min_size], preds_tf[:min_size], preds_xgb[:min_size]))\n",
    "            #res = meta_models_cat[k].predict(np.concatenate((stacked_predictions, test_src[k][:min_size]), axis=1))\n",
    "            res = meta_models_cat[k].predict(stacked_predictions)\n",
    "\n",
    "        rmse[k] = mean_squared_error(y_true[:min_size], res, squared=False)\n",
    "        mae[k] = mean_absolute_error(y_true[:min_size], res)\n",
    "        r2[k] = r2_score(y_true[:min_size], res)\n",
    "\n",
    "    print(\"Model\\tRMSE\\tMAE\\tR2\")\n",
    "    for k in range(8):\n",
    "        print(\n",
    "            f'{k+1}\\t{rmse[k]:.2f}\\t{mae[k]:.2f}\\t{r2[k]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tRMSE\tMAE\n",
      "1\t109.39\t80.21\n",
      "2\t130.98\t94.79\n",
      "3\t141.01\t101.02\n",
      "4\t146.40\t103.74\n",
      "5\t151.24\t107.16\n",
      "6\t154.41\t109.05\n",
      "7\t155.91\t109.82\n",
      "8\t155.52\t109.50\n"
     ]
    }
   ],
   "source": [
    "print_results('simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tRMSE\tMAE\tR2\n",
      "1\t107.55\t79.40\t0.57\n",
      "2\t130.07\t95.33\t0.38\n",
      "3\t140.31\t101.49\t0.27\n",
      "4\t146.14\t104.20\t0.21\n",
      "5\t151.17\t107.56\t0.16\n",
      "6\t154.33\t109.40\t0.12\n",
      "7\t155.58\t110.06\t0.11\n",
      "8\t154.70\t109.71\t0.12\n"
     ]
    }
   ],
   "source": [
    "print_results('lm', meta_models_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\tRMSE\tMAE\n",
      "1\t109.04\t80.14\n",
      "2\t131.19\t96.22\n",
      "3\t141.63\t102.33\n",
      "4\t147.21\t104.74\n",
      "5\t151.90\t107.77\n",
      "6\t154.89\t109.58\n",
      "7\t155.91\t110.33\n",
      "8\t155.72\t110.42\n"
     ]
    }
   ],
   "source": [
    "print_results('rf', meta_forest_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another ensemble was set up that could improve the resulting prediction based on models using future lags. In order not to skew the results, only data from the original validation set was used to train the ensemble model and tested on the original test data. \n",
    "\n",
    "We refer to a system that uses the outputs of other models as an ensemble. By combining other models, the ensemble should then achieve better prediction accuracy. In general, any kind of model can be used as an ensemble, but less complex ones are commonly used. For further information on ensemble models, we refer the reader to X.\n",
    "\n",
    "Several ensemble models have been proposed to improve the prediction accuracy. In addition to a simple averaging method, linear regression and decision trees (CITE) were also implemented. In addition to the predictions from the 4 models themselves (MLP, XGBoost, TFT and Transformer), the input data to the ensembles were added to the original models. In the case of decision trees, a grid search was also implemented to find the best hyperparameters.\n",
    "\n",
    "In the end, the best ensemble model turned out to be the linear model, which uses only the predictions from the original models as predictors. The more complex random forest struggled with overfitting despite hyperparameter optimization. Due to the fact that for ensemble models the data used for training is as large as the test data, the good generalization ability of the model is complicated.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
