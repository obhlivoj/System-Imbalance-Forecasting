{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import sklearn\n",
    "sklearn.set_config(enable_metadata_routing=True)\n",
    "\n",
    "from mapie.metrics import regression_coverage_score, regression_mean_width_score\n",
    "from mapie.subsample import BlockBootstrap\n",
    "from mapie.regression import MapieTimeSeriesRegressor, MapieRegressor\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'C:/Users/obhlivoj/DP/System-Imbalance-Forecasting/models/transformer_future_lags/')\n",
    "\n",
    "from config import get_config\n",
    "from train import get_ds, get_model, greedy_decode\n",
    "from transformer_dataset import TSDataset, causal_mask\n",
    "\n",
    "path = r'C:/Users/obhlivoj/DP/System-Imbalance-Forecasting/models/transformer_future_lags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg = get_config()\n",
    "\n",
    "cfg['tgt_seq_len'] = 1\n",
    "cfg['val_seq_len'] = 1\n",
    "cfg['num_epochs'] = 80\n",
    "\n",
    "train_scl, val_scl, test_scl, label_scaler = get_ds(cfg, return_raw=True)\n",
    "train_ds = TSDataset(\n",
    "    train_scl, cfg['src_seq_len'], cfg['tgt_seq_len'])\n",
    "val_ds = TSDataset(val_scl, cfg['src_seq_len'], cfg['tgt_seq_len'])\n",
    "test_ds = TSDataset(test_scl, cfg['src_seq_len'], cfg['tgt_seq_len'])\n",
    "\n",
    "# read json_info\n",
    "with open(f'{path}/final_single_step_param.json', 'r') as file:\n",
    "    best_params = json.load(file)\n",
    "\n",
    "for param, value in best_params['best_params'][0].items():\n",
    "    cfg[param] = value\n",
    "\n",
    "model = get_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mapiets = BlockBootstrap(\n",
    "    n_resamplings=4, n_blocks=10, overlapping=False, random_state=69\n",
    ")\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "for item in train_ds+val_ds:\n",
    "    x_list.append(torch.cat((item['encoder_input'], item['decoder_input'])).reshape(-1))\n",
    "    y_list.append(item[\"label\"].squeeze())\n",
    "\n",
    "X = torch.stack(x_list).numpy()\n",
    "y = torch.stack(y_list).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model, cfg, device, scaler):\n",
    "        self.model = model.to(device)\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.n_features = len(cfg['exo_vars']+cfg['target'])\n",
    "\n",
    "        self.enc_mask = torch.ones(1, cfg['src_seq_len'], cfg['src_seq_len']).bool()\n",
    "        self.dec_mask = causal_mask(cfg['tgt_seq_len'])\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert X and y to PyTorch tensors and move them to the specified device\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # Prepare dataset\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.cfg['batch_size'], shuffle=True)\n",
    "\n",
    "        # Initialize optimizer and loss function\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=cfg['lr'], eps=1e-9)\n",
    "        scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer, start_factor=1.0, end_factor=0.1, total_iters=30)\n",
    "        loss_fn = nn.MSELoss().to(self.device)\n",
    "\n",
    "        # Training loop\n",
    "        self.model.train()\n",
    "        for _ in range(self.cfg['num_epochs']):\n",
    "            for input, label in dataloader:\n",
    "                input_orig = input.reshape(-1, self.cfg['src_seq_len']+self.cfg['tgt_seq_len'], self.n_features)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                encoder_input = input_orig[:, :self.cfg['src_seq_len']].to(self.device)\n",
    "                decoder_input = input_orig[:, self.cfg['src_seq_len']:].to(self.device)\n",
    "                encoder_mask = self.enc_mask.to(self.device)\n",
    "                decoder_mask = self.dec_mask.to(self.device)\n",
    "\n",
    "                encoder_output = self.model.encode(encoder_input, encoder_mask)\n",
    "                decoder_output = self.model.decode(\n",
    "                    encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
    "                proj_output = self.model.project(decoder_output)\n",
    "\n",
    "                label = label.to(device)\n",
    "\n",
    "                # Compute the loss using MSE, backpropagate the loss, update the weights\n",
    "                loss = loss_fn(proj_output.view(-1), label.view(-1))\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        dataset = TensorDataset(X_tensor)\n",
    "        val_dataloader = DataLoader(dataset, batch_size=self.cfg['batch_size'], shuffle=False)\n",
    "\n",
    "        predicted = []\n",
    "        with torch.no_grad():\n",
    "            for input in val_dataloader:\n",
    "                input_orig = input[0].reshape(-1, self.cfg['src_seq_len']+self.cfg['tgt_seq_len'], self.n_features)\n",
    "\n",
    "                encoder_input = input_orig[:, :self.cfg['src_seq_len']].to(self.device)\n",
    "                decoder_input = input_orig[:, self.cfg['src_seq_len']:].to(self.device)\n",
    "                encoder_mask = self.enc_mask.to(self.device)\n",
    "\n",
    "                model_out = greedy_decode(\n",
    "                    self.model, self.cfg, encoder_input, encoder_mask, decoder_input, self.scaler, self.device)\n",
    "                output = model_out.detach().cpu()\n",
    "                predicted.append(output)\n",
    "\n",
    "            pred_torch = torch.cat(predicted)\n",
    "\n",
    "        # Move predictions to CPU for compatibility with scikit-learn\n",
    "        return pred_torch.numpy().squeeze()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return mean_squared_error(predictions, y, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def greedy_decode(self, encoder_input, encoder_mask, decoder_in):    \n",
    "#     encoder_output = self.model.encode(encoder_input, encoder_mask)\n",
    "#     decoder_input = decoder_in[:, 0:1, :].type_as(encoder_input).to(device)\n",
    "\n",
    "#     for i in range(cfg['val_seq_len']):\n",
    "#         # build a mask for the target (decoder input)\n",
    "#         decoder_mask = causal_mask(decoder_input.size(\n",
    "#             1)).type_as(encoder_mask).to(device)\n",
    "#         # calculate the output of the decoder\n",
    "#         out = model.decode(encoder_output, encoder_mask,\n",
    "#                             decoder_input, decoder_mask)\n",
    "#         # get the next token\n",
    "#         pred = model.project(out)\n",
    "#         if i == cfg['val_seq_len']-1:\n",
    "#             break\n",
    "#         pred_new = pred[:, -1, -1]\n",
    "#         scaled_pred = torch.tensor(self.scaler.transform(pred_new.view(-1, 1).cpu()))\n",
    "\n",
    "#         decoder_next = torch.clone(decoder_in[:, i+1, :].unsqueeze(1))\n",
    "#         decoder_next[:, :, 0] = scaled_pred\n",
    "#         decoder_input = torch.cat(\n",
    "#             [decoder_input, decoder_next.type_as(encoder_input).to(device)], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mapie = PyTorchRegressor(model, cfg, device, label_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MapieTimeSeriesRegressor(cv=BlockBootstrap(length=None, n_blocks=10, n_resamplings=4, overlapping=False,\n",
       "        random_state=69),\n",
       "                         estimator=PyTorchRegressor(cfg={&#x27;Nx&#x27;: 6,\n",
       "                                                         &#x27;batch_size&#x27;: 64,\n",
       "                                                         &#x27;d_ff&#x27;: 1024,\n",
       "                                                         &#x27;data_pickle_name&#x27;: &#x27;merged_data.pkl&#x27;,\n",
       "                                                         &#x27;diffs&#x27;: None,\n",
       "                                                         &#x27;dropout&#x27;: 0.1,\n",
       "                                                         &#x27;exo_vars&#x27;: [&#x27;month_sin&#x27;,\n",
       "                                                                      &#x27;month_cos&#x27;,\n",
       "                                                                      &#x27;day_sin&#x27;,\n",
       "                                                                      &#x27;day_cos&#x27;,\n",
       "                                                                      &#x27;weekday_sin&#x27;,\n",
       "                                                                      &#x27;weekday_cos&#x27;,\n",
       "                                                                      &#x27;hour_sin&#x27;,\n",
       "                                                                      &#x27;hour_...\n",
       "          (linear_2): Linear(in_features=1024, out_features=22, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_norm): LayerNormalization()\n",
       "  (projection_layer): LinearProjection(\n",
       "    (lin_project): Linear(in_features=22, out_features=1, bias=True)\n",
       "  )\n",
       "),\n",
       "                                                    scaler=StandardScaler()))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MapieTimeSeriesRegressor</label><div class=\"sk-toggleable__content\"><pre>MapieTimeSeriesRegressor(cv=BlockBootstrap(length=None, n_blocks=10, n_resamplings=4, overlapping=False,\n",
       "        random_state=69),\n",
       "                         estimator=PyTorchRegressor(cfg={&#x27;Nx&#x27;: 6,\n",
       "                                                         &#x27;batch_size&#x27;: 64,\n",
       "                                                         &#x27;d_ff&#x27;: 1024,\n",
       "                                                         &#x27;data_pickle_name&#x27;: &#x27;merged_data.pkl&#x27;,\n",
       "                                                         &#x27;diffs&#x27;: None,\n",
       "                                                         &#x27;dropout&#x27;: 0.1,\n",
       "                                                         &#x27;exo_vars&#x27;: [&#x27;month_sin&#x27;,\n",
       "                                                                      &#x27;month_cos&#x27;,\n",
       "                                                                      &#x27;day_sin&#x27;,\n",
       "                                                                      &#x27;day_cos&#x27;,\n",
       "                                                                      &#x27;weekday_sin&#x27;,\n",
       "                                                                      &#x27;weekday_cos&#x27;,\n",
       "                                                                      &#x27;hour_sin&#x27;,\n",
       "                                                                      &#x27;hour_...\n",
       "          (linear_2): Linear(in_features=1024, out_features=22, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_norm): LayerNormalization()\n",
       "  (projection_layer): LinearProjection(\n",
       "    (lin_project): Linear(in_features=22, out_features=1, bias=True)\n",
       "  )\n",
       "),\n",
       "                                                    scaler=StandardScaler()))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: PyTorchRegressor</label><div class=\"sk-toggleable__content\"><pre>PyTorchRegressor(cfg={&#x27;Nx&#x27;: 6, &#x27;batch_size&#x27;: 64, &#x27;d_ff&#x27;: 1024,\n",
       "                      &#x27;data_pickle_name&#x27;: &#x27;merged_data.pkl&#x27;, &#x27;diffs&#x27;: None,\n",
       "                      &#x27;dropout&#x27;: 0.1,\n",
       "                      &#x27;exo_vars&#x27;: [&#x27;month_sin&#x27;, &#x27;month_cos&#x27;, &#x27;day_sin&#x27;,\n",
       "                                   &#x27;day_cos&#x27;, &#x27;weekday_sin&#x27;, &#x27;weekday_cos&#x27;,\n",
       "                                   &#x27;hour_sin&#x27;, &#x27;hour_cos&#x27;, &#x27;quarter_hour_sin&#x27;,\n",
       "                                   &#x27;quarter_hour_cos&#x27;,\n",
       "                                   &#x27;measured_&amp;_upscaled_wind&#x27;,\n",
       "                                   &#x27;most_recent_forecast_wind&#x27;, &#x27;total_load&#x27;,\n",
       "                                   &#x27;most_recent_fore...\n",
       "          (linear_2): Linear(in_features=1024, out_features=22, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_norm): LayerNormalization()\n",
       "  (projection_layer): LinearProjection(\n",
       "    (lin_project): Linear(in_features=22, out_features=1, bias=True)\n",
       "  )\n",
       "),\n",
       "                 scaler=StandardScaler())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler: StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MapieTimeSeriesRegressor(cv=BlockBootstrap(length=None, n_blocks=10, n_resamplings=4, overlapping=False,\n",
       "        random_state=69),\n",
       "                         estimator=PyTorchRegressor(cfg={'Nx': 6,\n",
       "                                                         'batch_size': 64,\n",
       "                                                         'd_ff': 1024,\n",
       "                                                         'data_pickle_name': 'merged_data.pkl',\n",
       "                                                         'diffs': None,\n",
       "                                                         'dropout': 0.1,\n",
       "                                                         'exo_vars': ['month_sin',\n",
       "                                                                      'month_cos',\n",
       "                                                                      'day_sin',\n",
       "                                                                      'day_cos',\n",
       "                                                                      'weekday_sin',\n",
       "                                                                      'weekday_cos',\n",
       "                                                                      'hour_sin',\n",
       "                                                                      'hour_...\n",
       "          (linear_2): Linear(in_features=1024, out_features=22, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_norm): LayerNormalization()\n",
       "  (projection_layer): LinearProjection(\n",
       "    (lin_project): Linear(in_features=22, out_features=1, bias=True)\n",
       "  )\n",
       "),\n",
       "                                                    scaler=StandardScaler()))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapie_ts = MapieTimeSeriesRegressor(\n",
    "    mlp_mapie, method=\"enbpi\", cv=cv_mapiets, agg_function=\"mean\"\n",
    ")\n",
    "mapie_ts.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "for item in test_ds:\n",
    "    x_list.append(torch.cat((item['encoder_input'], item['decoder_input'])).reshape(-1))\n",
    "    y_list.append(item[\"label\"].squeeze())\n",
    "\n",
    "X_test = torch.stack(x_list).numpy()\n",
    "y_test = torch.stack(y_list).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pis = mapie_ts.predict(X_test, alpha=alpha)\n",
    "coverage = regression_coverage_score(y_test, y_pis[:, 0, 0], y_pis[:, 1, 0])\n",
    "width = regression_mean_width_score(y_pis[:, 0, 0], y_pis[:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.69202"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(mapie_ts.predict(X_test), y_test, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495.07245572408027"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_res = {\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_pis\": y_pis,\n",
    "    \"coverage\": coverage,\n",
    "    \"width\": width,\n",
    "    \"y_true\": y_test\n",
    "}\n",
    "\n",
    "with open('./results/trans_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(trans_res, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
